{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Edited Final_Notebook_RAVDESS_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lingelizabeth/senior-research/blob/master/Final_Notebook_RAVDESS_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNISLo8ty4U1",
        "colab_type": "text"
      },
      "source": [
        "#**RAVDESS Training and Evaluation**\n",
        "This notebook trains a neural network on analyzed RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song) speech data to predict 8 emotion classes. It utilizes a tiered model structure that first trains a Random Forest to determine the possitive/negative affect of a sample, then uses that predicted label as input into a neural net. The final neural net accuracy is 81.25% across all classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzt7D60jyIlU",
        "colab_type": "text"
      },
      "source": [
        "##**Load and clean data**\n",
        "The inputs are CSV files generated by openSMILE, an audio feature extraction package, and they include statistical measures of audio characteristics for each sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4e5XVuCR9W6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "\n",
        "from scipy.interpolate import *\n",
        "from scipy.signal import *\n",
        "from scipy.io import *\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, KFold\n",
        "from sklearn import tree\n",
        "from sklearn import preprocessing\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import cycle\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.metrics import roc_curve, auc, confusion_matrix, accuracy_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyIO-NhYRUxD",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "b76feef5-767f-4c4c-84c8-e4f7ed1a8fd1"
      },
      "source": [
        "uploaded = files.upload() # upload CSV output of openSMILE run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-19ce909f-f41c-437f-9f16-bb9855594d94\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-19ce909f-f41c-437f-9f16-bb9855594d94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving emobaseResults.csv to emobaseResults.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp0J6DTUSPlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read in CSV to pandas dataframe\n",
        "df = pd.read_csv(io.StringIO(uploaded['emobaseResults.csv'].decode('utf-8')))\n",
        "\n",
        "# use only every other line \n",
        "dropped = [i for i in range(1, 2804, 2)]\n",
        "df = df.drop(dropped)\n",
        "df = df.reindex(labels = range(1403), axis = 0, method = 'backfill')\n",
        "\n",
        "# drop unneccessary columns\n",
        "new_df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
        "new_df = new_df.drop([' name ', ' frameTime '], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l43emT5E2Lxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assigns each row as \"positive\" or \"negative\" emotion, based on its actual classification\n",
        "positive = [] # 1 for positive, 0 for negative\n",
        "for index, row in df.iterrows():\n",
        "  if(int(row[' emotion ']) in [1, 2, 3, 8]): \n",
        "    positive.append(1)\n",
        "  else:\n",
        "    positive.append(0)\n",
        "\n",
        "# append this column to the dataframe for later validation\n",
        "new_df['positive'] = pd.Series(positive)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLJNoYuwI1NA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1918
        },
        "outputId": "2ca507b7-3526-486f-bcb6-c6ca37c709d4"
      },
      "source": [
        "# scale the data to have a mean of 0 and unit variance (standard deviation of 1)\n",
        "scaler = StandardScaler()\n",
        "scaled_new_df = scaler.fit_transform(new_df)\n",
        "\n",
        "# fix indexing and drop labels for scaled dataframe\n",
        "scaled_new_df = pd.DataFrame(scaled_new_df, index = range(0, scaled_new_df.shape[0]), columns = new_df.columns.values)\n",
        "scaled_new_df = scaled_new_df.drop([' emotion ', 'positive'], axis=1) # doesn't include labels, so we use this as training\n",
        "scaled_new_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pcm_intensity_sma_max</th>\n",
              "      <th>pcm_intensity_sma_min</th>\n",
              "      <th>pcm_intensity_sma_range</th>\n",
              "      <th>pcm_intensity_sma_maxPos</th>\n",
              "      <th>pcm_intensity_sma_minPos</th>\n",
              "      <th>pcm_intensity_sma_amean</th>\n",
              "      <th>pcm_intensity_sma_linregc1</th>\n",
              "      <th>pcm_intensity_sma_linregc2</th>\n",
              "      <th>pcm_intensity_sma_linregerrA</th>\n",
              "      <th>pcm_intensity_sma_linregerrQ</th>\n",
              "      <th>pcm_intensity_sma_stddev</th>\n",
              "      <th>pcm_intensity_sma_skewness</th>\n",
              "      <th>pcm_intensity_sma_kurtosis</th>\n",
              "      <th>pcm_intensity_sma_quartile1</th>\n",
              "      <th>pcm_intensity_sma_quartile2</th>\n",
              "      <th>pcm_intensity_sma_quartile3</th>\n",
              "      <th>pcm_intensity_sma_iqr1-2</th>\n",
              "      <th>pcm_intensity_sma_iqr2-3</th>\n",
              "      <th>pcm_intensity_sma_iqr1-3</th>\n",
              "      <th>pcm_loudness_sma_max</th>\n",
              "      <th>pcm_loudness_sma_min</th>\n",
              "      <th>pcm_loudness_sma_range</th>\n",
              "      <th>pcm_loudness_sma_maxPos</th>\n",
              "      <th>pcm_loudness_sma_minPos</th>\n",
              "      <th>pcm_loudness_sma_amean</th>\n",
              "      <th>pcm_loudness_sma_linregc1</th>\n",
              "      <th>pcm_loudness_sma_linregc2</th>\n",
              "      <th>pcm_loudness_sma_linregerrA</th>\n",
              "      <th>pcm_loudness_sma_linregerrQ</th>\n",
              "      <th>pcm_loudness_sma_stddev</th>\n",
              "      <th>pcm_loudness_sma_skewness</th>\n",
              "      <th>pcm_loudness_sma_kurtosis</th>\n",
              "      <th>pcm_loudness_sma_quartile1</th>\n",
              "      <th>pcm_loudness_sma_quartile2</th>\n",
              "      <th>pcm_loudness_sma_quartile3</th>\n",
              "      <th>pcm_loudness_sma_iqr1-2</th>\n",
              "      <th>pcm_loudness_sma_iqr2-3</th>\n",
              "      <th>pcm_loudness_sma_iqr1-3</th>\n",
              "      <th>mfcc_sma[1]_max</th>\n",
              "      <th>mfcc_sma[1]_min</th>\n",
              "      <th>...</th>\n",
              "      <th>voiceProb_sma_de_iqr2-3</th>\n",
              "      <th>voiceProb_sma_de_iqr1-3</th>\n",
              "      <th>F0_sma_de_max</th>\n",
              "      <th>F0_sma_de_min</th>\n",
              "      <th>F0_sma_de_range</th>\n",
              "      <th>F0_sma_de_maxPos</th>\n",
              "      <th>F0_sma_de_minPos</th>\n",
              "      <th>F0_sma_de_amean</th>\n",
              "      <th>F0_sma_de_linregc1</th>\n",
              "      <th>F0_sma_de_linregc2</th>\n",
              "      <th>F0_sma_de_linregerrA</th>\n",
              "      <th>F0_sma_de_linregerrQ</th>\n",
              "      <th>F0_sma_de_stddev</th>\n",
              "      <th>F0_sma_de_skewness</th>\n",
              "      <th>F0_sma_de_kurtosis</th>\n",
              "      <th>F0_sma_de_quartile1</th>\n",
              "      <th>F0_sma_de_quartile2</th>\n",
              "      <th>F0_sma_de_quartile3</th>\n",
              "      <th>F0_sma_de_iqr1-2</th>\n",
              "      <th>F0_sma_de_iqr2-3</th>\n",
              "      <th>F0_sma_de_iqr1-3</th>\n",
              "      <th>F0env_sma_de_max</th>\n",
              "      <th>F0env_sma_de_min</th>\n",
              "      <th>F0env_sma_de_range</th>\n",
              "      <th>F0env_sma_de_maxPos</th>\n",
              "      <th>F0env_sma_de_minPos</th>\n",
              "      <th>F0env_sma_de_amean</th>\n",
              "      <th>F0env_sma_de_linregc1</th>\n",
              "      <th>F0env_sma_de_linregc2</th>\n",
              "      <th>F0env_sma_de_linregerrA</th>\n",
              "      <th>F0env_sma_de_linregerrQ</th>\n",
              "      <th>F0env_sma_de_stddev</th>\n",
              "      <th>F0env_sma_de_skewness</th>\n",
              "      <th>F0env_sma_de_kurtosis</th>\n",
              "      <th>F0env_sma_de_quartile1</th>\n",
              "      <th>F0env_sma_de_quartile2</th>\n",
              "      <th>F0env_sma_de_quartile3</th>\n",
              "      <th>F0env_sma_de_iqr1-2</th>\n",
              "      <th>F0env_sma_de_iqr2-3</th>\n",
              "      <th>F0env_sma_de_iqr1-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.358004</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.358004</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.372978</td>\n",
              "      <td>-0.110233</td>\n",
              "      <td>-0.360054</td>\n",
              "      <td>-0.370920</td>\n",
              "      <td>-0.207733</td>\n",
              "      <td>-0.370229</td>\n",
              "      <td>1.541522</td>\n",
              "      <td>1.614191</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245872</td>\n",
              "      <td>-0.355657</td>\n",
              "      <td>-0.245038</td>\n",
              "      <td>-0.354900</td>\n",
              "      <td>-0.355645</td>\n",
              "      <td>-0.688046</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.687917</td>\n",
              "      <td>-0.443099</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.839638</td>\n",
              "      <td>-0.526969</td>\n",
              "      <td>-0.788326</td>\n",
              "      <td>-0.743815</td>\n",
              "      <td>-0.549534</td>\n",
              "      <td>-0.736192</td>\n",
              "      <td>0.643848</td>\n",
              "      <td>0.283861</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.827298</td>\n",
              "      <td>-0.828167</td>\n",
              "      <td>-0.767562</td>\n",
              "      <td>-0.721929</td>\n",
              "      <td>-0.806741</td>\n",
              "      <td>0.818641</td>\n",
              "      <td>-1.720579</td>\n",
              "      <td>...</td>\n",
              "      <td>0.180522</td>\n",
              "      <td>0.189353</td>\n",
              "      <td>0.256959</td>\n",
              "      <td>1.270975</td>\n",
              "      <td>-0.581420</td>\n",
              "      <td>-0.455488</td>\n",
              "      <td>-0.427079</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.217784</td>\n",
              "      <td>-0.518448</td>\n",
              "      <td>-1.090196</td>\n",
              "      <td>-1.065740</td>\n",
              "      <td>-1.126694</td>\n",
              "      <td>1.592693</td>\n",
              "      <td>1.217624</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>0.820371</td>\n",
              "      <td>-0.240760</td>\n",
              "      <td>0.774369</td>\n",
              "      <td>1.051967</td>\n",
              "      <td>-0.355557</td>\n",
              "      <td>-0.831266</td>\n",
              "      <td>0.794192</td>\n",
              "      <td>-1.080115</td>\n",
              "      <td>-1.149000</td>\n",
              "      <td>0.077856</td>\n",
              "      <td>0.136447</td>\n",
              "      <td>1.663769</td>\n",
              "      <td>1.811967</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.361132</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.361132</td>\n",
              "      <td>-1.073305</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.371206</td>\n",
              "      <td>-0.114189</td>\n",
              "      <td>-0.356958</td>\n",
              "      <td>-0.368987</td>\n",
              "      <td>-0.207731</td>\n",
              "      <td>-0.369604</td>\n",
              "      <td>-0.353029</td>\n",
              "      <td>-0.548605</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245865</td>\n",
              "      <td>-0.355281</td>\n",
              "      <td>-0.245031</td>\n",
              "      <td>-0.354520</td>\n",
              "      <td>-0.355269</td>\n",
              "      <td>-0.635093</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.634938</td>\n",
              "      <td>-1.084394</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.791856</td>\n",
              "      <td>-0.515383</td>\n",
              "      <td>-0.738610</td>\n",
              "      <td>-0.700249</td>\n",
              "      <td>-0.527630</td>\n",
              "      <td>-0.663270</td>\n",
              "      <td>1.148368</td>\n",
              "      <td>0.694586</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.824063</td>\n",
              "      <td>-0.839349</td>\n",
              "      <td>-0.763744</td>\n",
              "      <td>-0.736828</td>\n",
              "      <td>-0.818357</td>\n",
              "      <td>0.338367</td>\n",
              "      <td>-0.535794</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.325261</td>\n",
              "      <td>-0.379922</td>\n",
              "      <td>-1.285977</td>\n",
              "      <td>2.629427</td>\n",
              "      <td>-2.154156</td>\n",
              "      <td>-0.446307</td>\n",
              "      <td>-0.390426</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.200300</td>\n",
              "      <td>-0.492623</td>\n",
              "      <td>-1.026204</td>\n",
              "      <td>-1.220737</td>\n",
              "      <td>-1.378064</td>\n",
              "      <td>2.441468</td>\n",
              "      <td>0.161574</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-0.167529</td>\n",
              "      <td>0.528702</td>\n",
              "      <td>-0.324628</td>\n",
              "      <td>1.091382</td>\n",
              "      <td>-0.580352</td>\n",
              "      <td>-1.591666</td>\n",
              "      <td>0.990488</td>\n",
              "      <td>-1.452352</td>\n",
              "      <td>-1.002366</td>\n",
              "      <td>-0.611619</td>\n",
              "      <td>-0.535874</td>\n",
              "      <td>0.667934</td>\n",
              "      <td>0.641477</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.361132</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.361132</td>\n",
              "      <td>-1.073305</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.371206</td>\n",
              "      <td>-0.114189</td>\n",
              "      <td>-0.356958</td>\n",
              "      <td>-0.368987</td>\n",
              "      <td>-0.207731</td>\n",
              "      <td>-0.369604</td>\n",
              "      <td>-0.353029</td>\n",
              "      <td>-0.548605</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245865</td>\n",
              "      <td>-0.355281</td>\n",
              "      <td>-0.245031</td>\n",
              "      <td>-0.354520</td>\n",
              "      <td>-0.355269</td>\n",
              "      <td>-0.635093</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.634938</td>\n",
              "      <td>-1.084394</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.791856</td>\n",
              "      <td>-0.515383</td>\n",
              "      <td>-0.738610</td>\n",
              "      <td>-0.700249</td>\n",
              "      <td>-0.527630</td>\n",
              "      <td>-0.663270</td>\n",
              "      <td>1.148368</td>\n",
              "      <td>0.694586</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.824063</td>\n",
              "      <td>-0.839349</td>\n",
              "      <td>-0.763744</td>\n",
              "      <td>-0.736828</td>\n",
              "      <td>-0.818357</td>\n",
              "      <td>0.338367</td>\n",
              "      <td>-0.535794</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.325261</td>\n",
              "      <td>-0.379922</td>\n",
              "      <td>-1.285977</td>\n",
              "      <td>2.629427</td>\n",
              "      <td>-2.154156</td>\n",
              "      <td>-0.446307</td>\n",
              "      <td>-0.390426</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.200300</td>\n",
              "      <td>-0.492623</td>\n",
              "      <td>-1.026204</td>\n",
              "      <td>-1.220737</td>\n",
              "      <td>-1.378064</td>\n",
              "      <td>2.441468</td>\n",
              "      <td>0.161574</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-0.167529</td>\n",
              "      <td>0.528702</td>\n",
              "      <td>-0.324628</td>\n",
              "      <td>1.091382</td>\n",
              "      <td>-0.580352</td>\n",
              "      <td>-1.591666</td>\n",
              "      <td>0.990488</td>\n",
              "      <td>-1.452352</td>\n",
              "      <td>-1.002366</td>\n",
              "      <td>-0.611619</td>\n",
              "      <td>-0.535874</td>\n",
              "      <td>0.667934</td>\n",
              "      <td>0.641477</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.353465</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.353465</td>\n",
              "      <td>-0.955607</td>\n",
              "      <td>-0.288195</td>\n",
              "      <td>-0.370076</td>\n",
              "      <td>-0.112802</td>\n",
              "      <td>-0.356216</td>\n",
              "      <td>-0.368376</td>\n",
              "      <td>-0.207722</td>\n",
              "      <td>-0.367325</td>\n",
              "      <td>1.868230</td>\n",
              "      <td>2.095782</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245872</td>\n",
              "      <td>-0.349271</td>\n",
              "      <td>-0.245038</td>\n",
              "      <td>-0.348454</td>\n",
              "      <td>-0.349258</td>\n",
              "      <td>-0.529608</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.529399</td>\n",
              "      <td>-0.967795</td>\n",
              "      <td>-0.286955</td>\n",
              "      <td>-0.733519</td>\n",
              "      <td>-0.499832</td>\n",
              "      <td>-0.678472</td>\n",
              "      <td>-0.616441</td>\n",
              "      <td>-0.517197</td>\n",
              "      <td>-0.631056</td>\n",
              "      <td>0.207418</td>\n",
              "      <td>0.074863</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.834378</td>\n",
              "      <td>-0.653266</td>\n",
              "      <td>-0.775920</td>\n",
              "      <td>-0.504458</td>\n",
              "      <td>-0.625064</td>\n",
              "      <td>0.750789</td>\n",
              "      <td>-0.107583</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.298794</td>\n",
              "      <td>-0.433784</td>\n",
              "      <td>-3.439340</td>\n",
              "      <td>3.418438</td>\n",
              "      <td>-3.725629</td>\n",
              "      <td>-0.207602</td>\n",
              "      <td>-0.216322</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.350098</td>\n",
              "      <td>-0.667709</td>\n",
              "      <td>-1.474935</td>\n",
              "      <td>-1.533535</td>\n",
              "      <td>-2.021954</td>\n",
              "      <td>-0.699495</td>\n",
              "      <td>0.268193</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-2.316540</td>\n",
              "      <td>2.235815</td>\n",
              "      <td>-2.726869</td>\n",
              "      <td>1.051967</td>\n",
              "      <td>-0.018366</td>\n",
              "      <td>-1.771022</td>\n",
              "      <td>1.196268</td>\n",
              "      <td>-1.695392</td>\n",
              "      <td>-2.249022</td>\n",
              "      <td>-2.286712</td>\n",
              "      <td>-2.955392</td>\n",
              "      <td>0.624438</td>\n",
              "      <td>0.168367</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.353465</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.353465</td>\n",
              "      <td>-0.955607</td>\n",
              "      <td>-0.288195</td>\n",
              "      <td>-0.370076</td>\n",
              "      <td>-0.112802</td>\n",
              "      <td>-0.356216</td>\n",
              "      <td>-0.368376</td>\n",
              "      <td>-0.207722</td>\n",
              "      <td>-0.367325</td>\n",
              "      <td>1.868230</td>\n",
              "      <td>2.095782</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245872</td>\n",
              "      <td>-0.349271</td>\n",
              "      <td>-0.245038</td>\n",
              "      <td>-0.348454</td>\n",
              "      <td>-0.349258</td>\n",
              "      <td>-0.529608</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.529399</td>\n",
              "      <td>-0.967795</td>\n",
              "      <td>-0.286955</td>\n",
              "      <td>-0.733519</td>\n",
              "      <td>-0.499832</td>\n",
              "      <td>-0.678472</td>\n",
              "      <td>-0.616441</td>\n",
              "      <td>-0.517197</td>\n",
              "      <td>-0.631056</td>\n",
              "      <td>0.207418</td>\n",
              "      <td>0.074863</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.834378</td>\n",
              "      <td>-0.653266</td>\n",
              "      <td>-0.775920</td>\n",
              "      <td>-0.504458</td>\n",
              "      <td>-0.625064</td>\n",
              "      <td>0.750789</td>\n",
              "      <td>-0.107583</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.298794</td>\n",
              "      <td>-0.433784</td>\n",
              "      <td>-3.439340</td>\n",
              "      <td>3.418438</td>\n",
              "      <td>-3.725629</td>\n",
              "      <td>-0.207602</td>\n",
              "      <td>-0.216322</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.350098</td>\n",
              "      <td>-0.667709</td>\n",
              "      <td>-1.474935</td>\n",
              "      <td>-1.533535</td>\n",
              "      <td>-2.021954</td>\n",
              "      <td>-0.699495</td>\n",
              "      <td>0.268193</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-2.316540</td>\n",
              "      <td>2.235815</td>\n",
              "      <td>-2.726869</td>\n",
              "      <td>1.051967</td>\n",
              "      <td>-0.018366</td>\n",
              "      <td>-1.771022</td>\n",
              "      <td>1.196268</td>\n",
              "      <td>-1.695392</td>\n",
              "      <td>-2.249022</td>\n",
              "      <td>-2.286712</td>\n",
              "      <td>-2.955392</td>\n",
              "      <td>0.624438</td>\n",
              "      <td>0.168367</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-0.362988</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.362988</td>\n",
              "      <td>-0.975223</td>\n",
              "      <td>-0.315957</td>\n",
              "      <td>-0.373408</td>\n",
              "      <td>-0.111544</td>\n",
              "      <td>-0.360225</td>\n",
              "      <td>-0.371965</td>\n",
              "      <td>-0.207742</td>\n",
              "      <td>-0.373179</td>\n",
              "      <td>-0.350657</td>\n",
              "      <td>-0.386572</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245886</td>\n",
              "      <td>-0.348675</td>\n",
              "      <td>-0.245052</td>\n",
              "      <td>-0.347852</td>\n",
              "      <td>-0.348662</td>\n",
              "      <td>-0.776739</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.776656</td>\n",
              "      <td>-1.026094</td>\n",
              "      <td>-0.314208</td>\n",
              "      <td>-0.784837</td>\n",
              "      <td>-0.479427</td>\n",
              "      <td>-0.738945</td>\n",
              "      <td>-0.691461</td>\n",
              "      <td>-0.542620</td>\n",
              "      <td>-0.712321</td>\n",
              "      <td>-0.272370</td>\n",
              "      <td>-0.485030</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.834378</td>\n",
              "      <td>-0.697338</td>\n",
              "      <td>-0.775920</td>\n",
              "      <td>-0.558618</td>\n",
              "      <td>-0.670843</td>\n",
              "      <td>0.759848</td>\n",
              "      <td>0.434563</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.622068</td>\n",
              "      <td>-0.451462</td>\n",
              "      <td>-2.308983</td>\n",
              "      <td>2.447618</td>\n",
              "      <td>-2.587175</td>\n",
              "      <td>-0.464669</td>\n",
              "      <td>0.544237</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.179490</td>\n",
              "      <td>-0.511459</td>\n",
              "      <td>-1.164215</td>\n",
              "      <td>-1.299180</td>\n",
              "      <td>-1.518313</td>\n",
              "      <td>0.777428</td>\n",
              "      <td>0.064389</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-0.895039</td>\n",
              "      <td>0.777590</td>\n",
              "      <td>-1.023629</td>\n",
              "      <td>1.032259</td>\n",
              "      <td>-0.748947</td>\n",
              "      <td>-0.825216</td>\n",
              "      <td>1.278318</td>\n",
              "      <td>-1.529423</td>\n",
              "      <td>-1.590483</td>\n",
              "      <td>-1.424927</td>\n",
              "      <td>-1.493605</td>\n",
              "      <td>1.079000</td>\n",
              "      <td>1.008916</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-0.362988</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.362988</td>\n",
              "      <td>-0.975223</td>\n",
              "      <td>-0.315957</td>\n",
              "      <td>-0.373408</td>\n",
              "      <td>-0.111544</td>\n",
              "      <td>-0.360225</td>\n",
              "      <td>-0.371965</td>\n",
              "      <td>-0.207742</td>\n",
              "      <td>-0.373179</td>\n",
              "      <td>-0.350657</td>\n",
              "      <td>-0.386572</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245886</td>\n",
              "      <td>-0.348675</td>\n",
              "      <td>-0.245052</td>\n",
              "      <td>-0.347852</td>\n",
              "      <td>-0.348662</td>\n",
              "      <td>-0.776739</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.776656</td>\n",
              "      <td>-1.026094</td>\n",
              "      <td>-0.314208</td>\n",
              "      <td>-0.784837</td>\n",
              "      <td>-0.479427</td>\n",
              "      <td>-0.738945</td>\n",
              "      <td>-0.691461</td>\n",
              "      <td>-0.542620</td>\n",
              "      <td>-0.712321</td>\n",
              "      <td>-0.272370</td>\n",
              "      <td>-0.485030</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.834378</td>\n",
              "      <td>-0.697338</td>\n",
              "      <td>-0.775920</td>\n",
              "      <td>-0.558618</td>\n",
              "      <td>-0.670843</td>\n",
              "      <td>0.759848</td>\n",
              "      <td>0.434563</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.622068</td>\n",
              "      <td>-0.451462</td>\n",
              "      <td>-2.308983</td>\n",
              "      <td>2.447618</td>\n",
              "      <td>-2.587175</td>\n",
              "      <td>-0.464669</td>\n",
              "      <td>0.544237</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.179490</td>\n",
              "      <td>-0.511459</td>\n",
              "      <td>-1.164215</td>\n",
              "      <td>-1.299180</td>\n",
              "      <td>-1.518313</td>\n",
              "      <td>0.777428</td>\n",
              "      <td>0.064389</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-0.895039</td>\n",
              "      <td>0.777590</td>\n",
              "      <td>-1.023629</td>\n",
              "      <td>1.032259</td>\n",
              "      <td>-0.748947</td>\n",
              "      <td>-0.825216</td>\n",
              "      <td>1.278318</td>\n",
              "      <td>-1.529423</td>\n",
              "      <td>-1.590483</td>\n",
              "      <td>-1.424927</td>\n",
              "      <td>-1.493605</td>\n",
              "      <td>1.079000</td>\n",
              "      <td>1.008916</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-0.366114</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.366114</td>\n",
              "      <td>0.044825</td>\n",
              "      <td>-0.302076</td>\n",
              "      <td>-0.376902</td>\n",
              "      <td>-0.104166</td>\n",
              "      <td>-0.366045</td>\n",
              "      <td>-0.375122</td>\n",
              "      <td>-0.207747</td>\n",
              "      <td>-0.376191</td>\n",
              "      <td>-0.618224</td>\n",
              "      <td>-0.653243</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245851</td>\n",
              "      <td>-0.357483</td>\n",
              "      <td>-0.245017</td>\n",
              "      <td>-0.356743</td>\n",
              "      <td>-0.357471</td>\n",
              "      <td>-0.822302</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.822241</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-0.300581</td>\n",
              "      <td>-0.877801</td>\n",
              "      <td>-0.327355</td>\n",
              "      <td>-0.875946</td>\n",
              "      <td>-0.837194</td>\n",
              "      <td>-0.571439</td>\n",
              "      <td>-0.818446</td>\n",
              "      <td>0.400580</td>\n",
              "      <td>0.015838</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.787582</td>\n",
              "      <td>-0.939010</td>\n",
              "      <td>-0.720681</td>\n",
              "      <td>-0.872348</td>\n",
              "      <td>-0.921879</td>\n",
              "      <td>0.546205</td>\n",
              "      <td>0.668386</td>\n",
              "      <td>...</td>\n",
              "      <td>0.151907</td>\n",
              "      <td>-0.280243</td>\n",
              "      <td>-0.406671</td>\n",
              "      <td>2.037249</td>\n",
              "      <td>-1.360377</td>\n",
              "      <td>-0.418764</td>\n",
              "      <td>-0.069708</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.102720</td>\n",
              "      <td>-0.333421</td>\n",
              "      <td>-0.945551</td>\n",
              "      <td>-0.989294</td>\n",
              "      <td>-1.012321</td>\n",
              "      <td>2.307869</td>\n",
              "      <td>0.520749</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>0.451113</td>\n",
              "      <td>0.152947</td>\n",
              "      <td>0.326748</td>\n",
              "      <td>1.150506</td>\n",
              "      <td>0.712216</td>\n",
              "      <td>-1.498774</td>\n",
              "      <td>0.512383</td>\n",
              "      <td>-0.930507</td>\n",
              "      <td>-1.154224</td>\n",
              "      <td>-0.313801</td>\n",
              "      <td>-0.224493</td>\n",
              "      <td>1.520185</td>\n",
              "      <td>1.546403</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-0.366114</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.366114</td>\n",
              "      <td>0.044825</td>\n",
              "      <td>-0.302076</td>\n",
              "      <td>-0.376902</td>\n",
              "      <td>-0.104166</td>\n",
              "      <td>-0.366045</td>\n",
              "      <td>-0.375122</td>\n",
              "      <td>-0.207747</td>\n",
              "      <td>-0.376191</td>\n",
              "      <td>-0.618224</td>\n",
              "      <td>-0.653243</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245851</td>\n",
              "      <td>-0.357483</td>\n",
              "      <td>-0.245017</td>\n",
              "      <td>-0.356743</td>\n",
              "      <td>-0.357471</td>\n",
              "      <td>-0.822302</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.822241</td>\n",
              "      <td>0.023298</td>\n",
              "      <td>-0.300581</td>\n",
              "      <td>-0.877801</td>\n",
              "      <td>-0.327355</td>\n",
              "      <td>-0.875946</td>\n",
              "      <td>-0.837194</td>\n",
              "      <td>-0.571439</td>\n",
              "      <td>-0.818446</td>\n",
              "      <td>0.400580</td>\n",
              "      <td>0.015838</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.787582</td>\n",
              "      <td>-0.939010</td>\n",
              "      <td>-0.720681</td>\n",
              "      <td>-0.872348</td>\n",
              "      <td>-0.921879</td>\n",
              "      <td>0.546205</td>\n",
              "      <td>0.668386</td>\n",
              "      <td>...</td>\n",
              "      <td>0.151907</td>\n",
              "      <td>-0.280243</td>\n",
              "      <td>-0.406671</td>\n",
              "      <td>2.037249</td>\n",
              "      <td>-1.360377</td>\n",
              "      <td>-0.418764</td>\n",
              "      <td>-0.069708</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>0.102720</td>\n",
              "      <td>-0.333421</td>\n",
              "      <td>-0.945551</td>\n",
              "      <td>-0.989294</td>\n",
              "      <td>-1.012321</td>\n",
              "      <td>2.307869</td>\n",
              "      <td>0.520749</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>0.451113</td>\n",
              "      <td>0.152947</td>\n",
              "      <td>0.326748</td>\n",
              "      <td>1.150506</td>\n",
              "      <td>0.712216</td>\n",
              "      <td>-1.498774</td>\n",
              "      <td>0.512383</td>\n",
              "      <td>-0.930507</td>\n",
              "      <td>-1.154224</td>\n",
              "      <td>-0.313801</td>\n",
              "      <td>-0.224493</td>\n",
              "      <td>1.520185</td>\n",
              "      <td>1.546403</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.885552</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.888054</td>\n",
              "      <td>-0.855739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-0.364902</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.364902</td>\n",
              "      <td>-1.073305</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.376528</td>\n",
              "      <td>-0.107858</td>\n",
              "      <td>-0.364452</td>\n",
              "      <td>-0.374960</td>\n",
              "      <td>-0.207746</td>\n",
              "      <td>-0.375740</td>\n",
              "      <td>0.107446</td>\n",
              "      <td>0.005695</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245443</td>\n",
              "      <td>-0.355376</td>\n",
              "      <td>-0.244607</td>\n",
              "      <td>-0.354623</td>\n",
              "      <td>-0.355364</td>\n",
              "      <td>-0.761933</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.761842</td>\n",
              "      <td>-1.084394</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.827125</td>\n",
              "      <td>-0.326744</td>\n",
              "      <td>-0.821455</td>\n",
              "      <td>-0.804437</td>\n",
              "      <td>-0.569008</td>\n",
              "      <td>-0.808697</td>\n",
              "      <td>-0.398174</td>\n",
              "      <td>-0.320469</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.698129</td>\n",
              "      <td>-0.818791</td>\n",
              "      <td>-0.615087</td>\n",
              "      <td>-0.756595</td>\n",
              "      <td>-0.797002</td>\n",
              "      <td>0.837342</td>\n",
              "      <td>1.483082</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100884</td>\n",
              "      <td>-0.361128</td>\n",
              "      <td>-1.991096</td>\n",
              "      <td>1.476945</td>\n",
              "      <td>-1.874040</td>\n",
              "      <td>0.132093</td>\n",
              "      <td>1.039058</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>-0.119403</td>\n",
              "      <td>-0.054719</td>\n",
              "      <td>-0.928249</td>\n",
              "      <td>-1.056052</td>\n",
              "      <td>-1.111167</td>\n",
              "      <td>-0.289066</td>\n",
              "      <td>0.132250</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-0.877583</td>\n",
              "      <td>1.339674</td>\n",
              "      <td>-1.204082</td>\n",
              "      <td>1.111090</td>\n",
              "      <td>0.726266</td>\n",
              "      <td>-0.187370</td>\n",
              "      <td>1.172151</td>\n",
              "      <td>-1.216683</td>\n",
              "      <td>-1.366187</td>\n",
              "      <td>-1.545021</td>\n",
              "      <td>-1.656133</td>\n",
              "      <td>0.750519</td>\n",
              "      <td>0.748392</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.835473</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.837634</td>\n",
              "      <td>-0.824847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-0.364902</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.364902</td>\n",
              "      <td>-1.073305</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.376528</td>\n",
              "      <td>-0.107858</td>\n",
              "      <td>-0.364452</td>\n",
              "      <td>-0.374960</td>\n",
              "      <td>-0.207746</td>\n",
              "      <td>-0.375740</td>\n",
              "      <td>0.107446</td>\n",
              "      <td>0.005695</td>\n",
              "      <td>-0.151970</td>\n",
              "      <td>-0.245443</td>\n",
              "      <td>-0.355376</td>\n",
              "      <td>-0.244607</td>\n",
              "      <td>-0.354623</td>\n",
              "      <td>-0.355364</td>\n",
              "      <td>-0.761933</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.761842</td>\n",
              "      <td>-1.084394</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.827125</td>\n",
              "      <td>-0.326744</td>\n",
              "      <td>-0.821455</td>\n",
              "      <td>-0.804437</td>\n",
              "      <td>-0.569008</td>\n",
              "      <td>-0.808697</td>\n",
              "      <td>-0.398174</td>\n",
              "      <td>-0.320469</td>\n",
              "      <td>-0.772470</td>\n",
              "      <td>-0.698129</td>\n",
              "      <td>-0.818791</td>\n",
              "      <td>-0.615087</td>\n",
              "      <td>-0.756595</td>\n",
              "      <td>-0.797002</td>\n",
              "      <td>0.837342</td>\n",
              "      <td>1.483082</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100884</td>\n",
              "      <td>-0.361128</td>\n",
              "      <td>-1.991096</td>\n",
              "      <td>1.476945</td>\n",
              "      <td>-1.874040</td>\n",
              "      <td>0.132093</td>\n",
              "      <td>1.039058</td>\n",
              "      <td>-0.419629</td>\n",
              "      <td>-0.119403</td>\n",
              "      <td>-0.054719</td>\n",
              "      <td>-0.928249</td>\n",
              "      <td>-1.056052</td>\n",
              "      <td>-1.111167</td>\n",
              "      <td>-0.289066</td>\n",
              "      <td>0.132250</td>\n",
              "      <td>0.765308</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>-0.749861</td>\n",
              "      <td>-0.765465</td>\n",
              "      <td>-0.749870</td>\n",
              "      <td>-0.762834</td>\n",
              "      <td>-0.877583</td>\n",
              "      <td>1.339674</td>\n",
              "      <td>-1.204082</td>\n",
              "      <td>1.111090</td>\n",
              "      <td>0.726266</td>\n",
              "      <td>-0.187370</td>\n",
              "      <td>1.172151</td>\n",
              "      <td>-1.216683</td>\n",
              "      <td>-1.366187</td>\n",
              "      <td>-1.545021</td>\n",
              "      <td>-1.656133</td>\n",
              "      <td>0.750519</td>\n",
              "      <td>0.748392</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>-0.835473</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>-0.837634</td>\n",
              "      <td>-0.824847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>-0.366151</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.366151</td>\n",
              "      <td>-1.210619</td>\n",
              "      <td>-0.093862</td>\n",
              "      <td>-0.376994</td>\n",
              "      <td>-0.102996</td>\n",
              "      <td>-0.366469</td>\n",
              "      <td>-0.375121</td>\n",
              "      <td>-0.207747</td>\n",
              "      <td>-0.375955</td>\n",
              "      <td>-0.480276</td>\n",
              "      <td>-0.613111</td>\n",
              "      <td>-0.150882</td>\n",
              "      <td>-0.245791</td>\n",
              "      <td>-0.357869</td>\n",
              "      <td>-0.244971</td>\n",
              "      <td>-0.357133</td>\n",
              "      <td>-0.357856</td>\n",
              "      <td>-0.823252</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.823191</td>\n",
              "      <td>-1.220426</td>\n",
              "      <td>-0.096183</td>\n",
              "      <td>-0.907868</td>\n",
              "      <td>-0.168673</td>\n",
              "      <td>-0.933638</td>\n",
              "      <td>-0.865420</td>\n",
              "      <td>-0.575368</td>\n",
              "      <td>-0.834140</td>\n",
              "      <td>1.345839</td>\n",
              "      <td>0.901730</td>\n",
              "      <td>-0.532763</td>\n",
              "      <td>-0.745094</td>\n",
              "      <td>-0.958948</td>\n",
              "      <td>-0.735382</td>\n",
              "      <td>-0.912043</td>\n",
              "      <td>-0.959195</td>\n",
              "      <td>0.794513</td>\n",
              "      <td>1.315391</td>\n",
              "      <td>...</td>\n",
              "      <td>1.602713</td>\n",
              "      <td>1.524205</td>\n",
              "      <td>0.941813</td>\n",
              "      <td>-0.951111</td>\n",
              "      <td>1.028670</td>\n",
              "      <td>-0.639107</td>\n",
              "      <td>-0.656163</td>\n",
              "      <td>0.483915</td>\n",
              "      <td>3.157047</td>\n",
              "      <td>-3.030266</td>\n",
              "      <td>1.352273</td>\n",
              "      <td>1.429733</td>\n",
              "      <td>1.339484</td>\n",
              "      <td>-0.165739</td>\n",
              "      <td>-1.043594</td>\n",
              "      <td>-1.384387</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>1.504896</td>\n",
              "      <td>1.384789</td>\n",
              "      <td>1.504792</td>\n",
              "      <td>1.455774</td>\n",
              "      <td>0.800138</td>\n",
              "      <td>0.304087</td>\n",
              "      <td>0.568163</td>\n",
              "      <td>-0.997634</td>\n",
              "      <td>-0.158862</td>\n",
              "      <td>0.195185</td>\n",
              "      <td>-2.080170</td>\n",
              "      <td>1.411741</td>\n",
              "      <td>0.705372</td>\n",
              "      <td>0.986288</td>\n",
              "      <td>0.986725</td>\n",
              "      <td>-0.039165</td>\n",
              "      <td>-0.167349</td>\n",
              "      <td>0.548626</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>0.403104</td>\n",
              "      <td>-0.547909</td>\n",
              "      <td>0.409381</td>\n",
              "      <td>0.018134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1401</th>\n",
              "      <td>-0.364983</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.364983</td>\n",
              "      <td>-0.504431</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.377189</td>\n",
              "      <td>-0.104148</td>\n",
              "      <td>-0.366371</td>\n",
              "      <td>-0.375291</td>\n",
              "      <td>-0.207746</td>\n",
              "      <td>-0.375244</td>\n",
              "      <td>0.801377</td>\n",
              "      <td>0.469287</td>\n",
              "      <td>-0.151426</td>\n",
              "      <td>-0.245851</td>\n",
              "      <td>-0.358853</td>\n",
              "      <td>-0.245024</td>\n",
              "      <td>-0.358125</td>\n",
              "      <td>-0.358840</td>\n",
              "      <td>-0.826854</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.826796</td>\n",
              "      <td>-0.520831</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.947813</td>\n",
              "      <td>-0.123074</td>\n",
              "      <td>-0.990814</td>\n",
              "      <td>-0.912929</td>\n",
              "      <td>-0.585890</td>\n",
              "      <td>-0.879491</td>\n",
              "      <td>1.428881</td>\n",
              "      <td>1.223292</td>\n",
              "      <td>-0.577770</td>\n",
              "      <td>-0.787582</td>\n",
              "      <td>-0.991019</td>\n",
              "      <td>-0.773359</td>\n",
              "      <td>-0.936264</td>\n",
              "      <td>-0.989392</td>\n",
              "      <td>1.895437</td>\n",
              "      <td>2.616064</td>\n",
              "      <td>...</td>\n",
              "      <td>1.285634</td>\n",
              "      <td>1.261871</td>\n",
              "      <td>0.532023</td>\n",
              "      <td>-0.585734</td>\n",
              "      <td>0.608383</td>\n",
              "      <td>-0.795183</td>\n",
              "      <td>-0.811940</td>\n",
              "      <td>0.356222</td>\n",
              "      <td>0.004078</td>\n",
              "      <td>-0.026736</td>\n",
              "      <td>1.036753</td>\n",
              "      <td>1.071378</td>\n",
              "      <td>1.069156</td>\n",
              "      <td>-0.061590</td>\n",
              "      <td>-1.023185</td>\n",
              "      <td>-0.909279</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>1.063328</td>\n",
              "      <td>0.909557</td>\n",
              "      <td>1.063242</td>\n",
              "      <td>0.994440</td>\n",
              "      <td>0.660173</td>\n",
              "      <td>-0.059443</td>\n",
              "      <td>0.576526</td>\n",
              "      <td>-0.918803</td>\n",
              "      <td>-0.088614</td>\n",
              "      <td>1.236819</td>\n",
              "      <td>-1.473180</td>\n",
              "      <td>1.369502</td>\n",
              "      <td>0.351742</td>\n",
              "      <td>0.302584</td>\n",
              "      <td>0.409727</td>\n",
              "      <td>0.260495</td>\n",
              "      <td>0.279172</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>0.453426</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>0.460046</td>\n",
              "      <td>-0.029749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1402</th>\n",
              "      <td>-0.364983</td>\n",
              "      <td>-0.063948</td>\n",
              "      <td>-0.364983</td>\n",
              "      <td>-0.504431</td>\n",
              "      <td>-0.357600</td>\n",
              "      <td>-0.377189</td>\n",
              "      <td>-0.104148</td>\n",
              "      <td>-0.366371</td>\n",
              "      <td>-0.375291</td>\n",
              "      <td>-0.207746</td>\n",
              "      <td>-0.375244</td>\n",
              "      <td>0.801377</td>\n",
              "      <td>0.469287</td>\n",
              "      <td>-0.151426</td>\n",
              "      <td>-0.245851</td>\n",
              "      <td>-0.358853</td>\n",
              "      <td>-0.245024</td>\n",
              "      <td>-0.358125</td>\n",
              "      <td>-0.358840</td>\n",
              "      <td>-0.826854</td>\n",
              "      <td>-0.22482</td>\n",
              "      <td>-0.826796</td>\n",
              "      <td>-0.520831</td>\n",
              "      <td>-0.355088</td>\n",
              "      <td>-0.947813</td>\n",
              "      <td>-0.123074</td>\n",
              "      <td>-0.990814</td>\n",
              "      <td>-0.912929</td>\n",
              "      <td>-0.585890</td>\n",
              "      <td>-0.879491</td>\n",
              "      <td>1.428881</td>\n",
              "      <td>1.223292</td>\n",
              "      <td>-0.577770</td>\n",
              "      <td>-0.787582</td>\n",
              "      <td>-0.991019</td>\n",
              "      <td>-0.773359</td>\n",
              "      <td>-0.936264</td>\n",
              "      <td>-0.989392</td>\n",
              "      <td>1.895437</td>\n",
              "      <td>2.616064</td>\n",
              "      <td>...</td>\n",
              "      <td>1.285634</td>\n",
              "      <td>1.261871</td>\n",
              "      <td>0.532023</td>\n",
              "      <td>-0.585734</td>\n",
              "      <td>0.608383</td>\n",
              "      <td>-0.795183</td>\n",
              "      <td>-0.811940</td>\n",
              "      <td>0.356222</td>\n",
              "      <td>0.004078</td>\n",
              "      <td>-0.026736</td>\n",
              "      <td>1.036753</td>\n",
              "      <td>1.071378</td>\n",
              "      <td>1.069156</td>\n",
              "      <td>-0.061590</td>\n",
              "      <td>-1.023185</td>\n",
              "      <td>-0.909279</td>\n",
              "      <td>0.004354</td>\n",
              "      <td>1.063328</td>\n",
              "      <td>0.909557</td>\n",
              "      <td>1.063242</td>\n",
              "      <td>0.994440</td>\n",
              "      <td>0.660173</td>\n",
              "      <td>-0.059443</td>\n",
              "      <td>0.576526</td>\n",
              "      <td>-0.918803</td>\n",
              "      <td>-0.088614</td>\n",
              "      <td>1.236819</td>\n",
              "      <td>-1.473180</td>\n",
              "      <td>1.369502</td>\n",
              "      <td>0.351742</td>\n",
              "      <td>0.302584</td>\n",
              "      <td>0.409727</td>\n",
              "      <td>0.260495</td>\n",
              "      <td>0.279172</td>\n",
              "      <td>0.736455</td>\n",
              "      <td>-0.134387</td>\n",
              "      <td>0.453426</td>\n",
              "      <td>-0.733749</td>\n",
              "      <td>0.460046</td>\n",
              "      <td>-0.029749</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1403 rows × 988 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       pcm_intensity_sma_max   ...   F0env_sma_de_iqr1-3 \n",
              "0                   -0.358004  ...              -0.855739\n",
              "1                   -0.361132  ...              -0.855739\n",
              "2                   -0.361132  ...              -0.855739\n",
              "3                   -0.353465  ...              -0.855739\n",
              "4                   -0.353465  ...              -0.855739\n",
              "5                   -0.362988  ...              -0.855739\n",
              "6                   -0.362988  ...              -0.855739\n",
              "7                   -0.366114  ...              -0.855739\n",
              "8                   -0.366114  ...              -0.855739\n",
              "9                   -0.364902  ...              -0.824847\n",
              "10                  -0.364902  ...              -0.824847\n",
              "11                  -0.363935  ...              -0.855739\n",
              "12                  -0.363935  ...              -0.855739\n",
              "13                  -0.358483  ...              -0.855739\n",
              "14                  -0.358483  ...              -0.855739\n",
              "15                  -0.366996  ...              -0.855739\n",
              "16                  -0.366996  ...              -0.855739\n",
              "17                  -0.367356  ...              -0.780872\n",
              "18                  -0.367356  ...              -0.780872\n",
              "19                  -0.367285  ...              -0.855739\n",
              "20                  -0.367285  ...              -0.855739\n",
              "21                  -0.366147  ...              -0.855739\n",
              "22                  -0.366147  ...              -0.855739\n",
              "23                  -0.355493  ...              -0.855739\n",
              "24                  -0.355493  ...              -0.855739\n",
              "25                  -0.349888  ...              -0.583727\n",
              "26                  -0.349888  ...              -0.583727\n",
              "27                  -0.346490  ...              -0.855739\n",
              "28                  -0.346490  ...              -0.855739\n",
              "29                  -0.360551  ...              -0.855739\n",
              "...                       ...  ...                    ...\n",
              "1373                -0.333099  ...              -0.855739\n",
              "1374                -0.333099  ...              -0.855739\n",
              "1375                -0.327772  ...              -0.855739\n",
              "1376                -0.327772  ...              -0.855739\n",
              "1377                -0.325009  ...              -0.855739\n",
              "1378                -0.325009  ...              -0.855739\n",
              "1379                -0.285999  ...              -0.014832\n",
              "1380                -0.285999  ...              -0.014832\n",
              "1381                -0.240095  ...              -0.432213\n",
              "1382                -0.240095  ...              -0.432213\n",
              "1383                -0.286448  ...              -0.720570\n",
              "1384                -0.286448  ...              -0.720570\n",
              "1385                -0.358968  ...               0.059632\n",
              "1386                -0.358968  ...               0.059632\n",
              "1387                -0.361073  ...               0.447680\n",
              "1388                -0.361073  ...               0.447680\n",
              "1389                -0.354118  ...               2.335878\n",
              "1390                -0.354118  ...               2.335878\n",
              "1391                -0.362831  ...               0.602101\n",
              "1392                -0.362831  ...               0.602101\n",
              "1393                -0.366672  ...               1.008409\n",
              "1394                -0.366672  ...               1.008409\n",
              "1395                -0.359514  ...               0.130278\n",
              "1396                -0.359514  ...               0.130278\n",
              "1397                -0.367126  ...               1.719922\n",
              "1398                -0.367126  ...               1.719922\n",
              "1399                -0.366151  ...               0.018134\n",
              "1400                -0.366151  ...               0.018134\n",
              "1401                -0.364983  ...              -0.029749\n",
              "1402                -0.364983  ...              -0.029749\n",
              "\n",
              "[1403 rows x 988 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjVB0AP15apj",
        "colab_type": "text"
      },
      "source": [
        "## **Binary classification of positive and negative emotions**\n",
        "\n",
        "My model architecture finding was a significant increase in emotion classification accuracy when first considering a binary classification: **is the sample \"positive\" or \"negative\"?** Emotions like happiness, surprise, neutral and calm were considered positive, while anger, fear, sadness, and disgust were considered negative. \n",
        "\n",
        "I use a Random Forest for binary classification for this dataset. The final accuracy is 92.88%\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRhDs9zJaJ-N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "a8e564c2-f942-4e64-f533-bc5aec79c023"
      },
      "source": [
        "# Gridsearch to determine best parameters\n",
        "parameters = {'min_samples_split':[6, 7, 9], 'min_samples_leaf':[3, 4], 'max_features': [18, 20, 50]}\n",
        "rf = RandomForestClassifier(n_estimators = 99, criterion = 'gini', max_depth = 7)\n",
        "clf = GridSearchCV(rf, parameters, cv=5)\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise',\n",
              "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=7, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=99, n_jobs=1,\n",
              "            oob_score=False, random_state=None, verbose=0,\n",
              "            warm_start=False),\n",
              "       fit_params=None, iid=True, n_jobs=1,\n",
              "       param_grid={'min_samples_split': [6, 7, 9], 'min_samples_leaf': [3, 4], 'max_features': [18, 20, 50]},\n",
              "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
              "       scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7AboYtJfp0M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8050a727-7c6d-4620-b984-7e8df4f7eacb"
      },
      "source": [
        "#prints best parameters from Grid Search\n",
        "clf.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_features': 50, 'min_samples_leaf': 3, 'min_samples_split': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVrLc_4OS_yQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "3782e2c2-4c3b-44a1-aed8-61e82ae820af"
      },
      "source": [
        "# split into training and validation data\n",
        "X_train, X_val, y_train, y_val = train_test_split(scaled_new_df, new_df['positive'], test_size = .25, random_state = None)\n",
        "\n",
        "# create random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=99, criterion='gini', max_depth=7, min_samples_split = 6, min_samples_leaf=3, max_features=50, random_state=None)\n",
        "rf.fit(X_train, y_train)\n",
        "y_predict = rf.predict(X_val)\n",
        "\n",
        "# evaluate model, accuracy of 92.8%\n",
        "print(confusion_matrix(y_val, y_predict))\n",
        "print(accuracy_score(y_val, y_predict))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[171  12]\n",
            " [ 13 155]]\n",
            "0.9287749287749287\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9wKUgeXFfN-",
        "colab_type": "text"
      },
      "source": [
        "### Confusion Matrix for Positive/Negative Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVOdbr4L3pum",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "![Random Forest Conudsion Matrix](https://drive.google.com/uc?export=view&id=1HMGmkUdFmXY_KYRfD0EXe0TvzJQglu5m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jJOHmIXWiLj",
        "colab_type": "text"
      },
      "source": [
        "## **Classifying Emotions with a Neural Net**\n",
        "Now, we will predict 8 emotion classes (happy, sad, neutral, calm, fear, anger, disgust, and surprise) using a neural net, with the audio features *and* the previous positive/negative prediction as input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jENXJvCDeCKg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add the random forest predictions as an input column \n",
        "predicted_pos = rf.predict(scaled_new_df)\n",
        "scaled_new_df['positive'] = pd.Series(predicted_pos)\n",
        "\n",
        "# split training and testing data\n",
        "train_data, val_data, train_labels, val_labels = \n",
        "  train_test_split(\n",
        "      scaled_new_df.loc[X_train.index],  # this training data excludes test data from the previous split\n",
        "      new_df.loc[y_train.index][' emotion '].astype(int)-1, \n",
        "      test_size = .2, \n",
        "      random_state = None\n",
        "  )\n",
        "print(train_data.shape)\n",
        "\n",
        "# reshape the data for training \n",
        "train_data = np.array(train_data).reshape((train_data.shape[0], train_data.shape[1], 1))\n",
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzZYYmFPcJ73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "outputId": "00484e34-144f-4d7e-f8b0-507d0a6c2a0e"
      },
      "source": [
        "# build model!\n",
        "model = []\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Dense(16, input_shape = train_data[0].shape))\n",
        "model.add(Dense(16, activation='sigmoid', kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
        "model.add(tf.keras.layers.Dropout(.25))\n",
        "model.add(Dense(4, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(.25))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(8, activation = tf.nn.softmax)) \n",
        "  \n",
        "sgd = tf.keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.001, nesterov=False)\n",
        "model.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics =[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 989, 16)           32        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 989, 16)           272       \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 989, 16)           0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 989, 4)            68        \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 989, 4)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3956)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 31656     \n",
            "=================================================================\n",
            "Total params: 32,028\n",
            "Trainable params: 32,028\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1slj3uwcod3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3464
        },
        "outputId": "6479019a-2e19-46dc-ead8-dca6718b307b"
      },
      "source": [
        "y = model.fit(train_data, to_categorical(train_labels), verbose = True, epochs = 100, validation_split = .2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 672 samples, validate on 169 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "672/672 [==============================] - 1s 1ms/sample - loss: 2.7825 - acc: 0.1354 - val_loss: 2.1601 - val_acc: 0.2012\n",
            "Epoch 2/100\n",
            "672/672 [==============================] - 0s 208us/sample - loss: 2.2424 - acc: 0.1786 - val_loss: 1.9896 - val_acc: 0.4083\n",
            "Epoch 3/100\n",
            "672/672 [==============================] - 0s 194us/sample - loss: 2.0920 - acc: 0.2440 - val_loss: 1.9019 - val_acc: 0.4083\n",
            "Epoch 4/100\n",
            "672/672 [==============================] - 0s 220us/sample - loss: 1.9760 - acc: 0.3155 - val_loss: 1.8414 - val_acc: 0.3669\n",
            "Epoch 5/100\n",
            "672/672 [==============================] - 0s 183us/sample - loss: 1.9356 - acc: 0.3229 - val_loss: 1.7001 - val_acc: 0.4260\n",
            "..."
            "Epoch 100/100\n",
            "672/672 [==============================] - 0s 167us/sample - loss: 0.2226 - acc: 0.9747 - val_loss: 0.6979 - val_acc: 0.8107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBQZete39RfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "cf834f51-6e47-4465-8f06-dcdfddc95161"
      },
      "source": [
        "# reshape validation data for model\n",
        "val_data = np.array(val_data).reshape((val_data.shape[0], val_data.shape[1], 1))\n",
        "\n",
        "# predict on validation data and print evaluations\n",
        "y_pred_proba = model.predict(val_data)\n",
        "print(confusion_matrix(val_labels, np.argmax(y_pred_proba, axis=1)))\n",
        "print(accuracy_score(val_labels, np.argmax(y_pred_proba, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[18  2  0  1  1  0  0  0]\n",
            " [ 0 52  0  1  0  0  0  0]\n",
            " [ 0  0 42  0  4  2  0  2]\n",
            " [ 0  0  0 36  0  3  0  0]\n",
            " [ 0  0  0  0 35  0  2  1]\n",
            " [ 1  0  0  1  0 39  0  1]\n",
            " [ 0  0  0  1  0  2 50  0]\n",
            " [ 0  0  0  0  0  0  0 54]]\n",
            "0.9287749287749287\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwqJbp7U5MeZ",
        "colab_type": "text"
      },
      "source": [
        "### K Fold Cross Validation\n",
        "The output of this section has been omitted for brevity. The K-Fold cross validation accuracy was 98.29%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjRCFKg34T2w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get data and labels for K-fold cross validation \n",
        "data = np.array(scaled_new_df.loc[X_train.index])\n",
        "all_labels= new_df.loc[y_train.index][' emotion '].astype(int)-1\n",
        "print(len(data))\n",
        "\n",
        "# prepare K-fold cross validation\n",
        "kfold = KFold(3, False, 1)\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(data):\n",
        "  model.fit(data[train].reshape(len(train), data.shape[1], 1), to_categorical(all_labels.iloc[train]), verbose=True, epochs = 100, validation_split=.1)\n",
        "  y_pred_temp = model.predict(data[test].reshape(len(test), data.shape[1], 1))\n",
        "  print(accuracy_score(all_labels.iloc[test], np.argmax(y_pred_temp, axis=1))) # print validation accuracy per split\n",
        "  model.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNfiREgG5tZU",
        "colab_type": "text"
      },
      "source": [
        "### Final Model Evaluation\n",
        "We evaluate the neural net test accuracy on data held back in the first data split, which neither the Random Forest or neural net has trained on.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZAnu_pKiF_6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "c8c21249-861e-41e1-ba5d-6bc9f135fe3d"
      },
      "source": [
        "X_val_predicted_pos = rf.predict(X_val) #add positive column to validation data\n",
        "X_val_w_positive = X_val\n",
        "X_val_w_positive['positive'] = X_val_predicted_pos\n",
        "\n",
        "#reshape the validation data to input into the model\n",
        "X_val_w_positive = np.array(X_val_w_positive).reshape((X_val_w_positive.shape[0], X_val_w_positive.shape[1], 1)) \n",
        "\n",
        "# predict on the data and print evaluation metrics\n",
        "y_pred_X_val = model.predict(X_val_w_positive)\n",
        "print(confusion_matrix(new_df.loc[y_val.index][' emotion '].astype(int)-1, np.argmax(y_pred_X_val, axis=1))) \n",
        "print(accuracy_score(new_df.loc[y_val.index][' emotion '].astype(int)-1, np.argmax(y_pred_X_val, axis=1)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[15  2  0  3  0  0  1  2]\n",
            " [ 3 52  0  1  0  0  0  0]\n",
            " [ 1  3 38  1  0  0  0  1]\n",
            " [ 0  3  0 35  0  0  3  2]\n",
            " [ 0  0  3  2 35  0  2  0]\n",
            " [ 0  3  1  0  0 41  0  1]\n",
            " [ 3  1  1  2  2  3 37  3]\n",
            " [ 0  1  1  3  0  3  0 37]]\n",
            "0.8262108262108262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yriAz5yd42w9",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://drive.google.com/uc?export=view&id=1WdRm1pI_de0eWPIEpiRastAUfwmp5OQJ)"
      ]
    }
  ]
}
